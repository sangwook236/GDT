[-] General.
	- Site.
		https://github.com/PaddlePaddle/PaddleOCR

[-] Usage (PaddleOCR).
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/quickstart_en.md

	- Chinese and English model.
		Detection, direction classification and recognition: set the parameter --use_gpu false to disable the gpu device.
			paddleocr --image_dir ./imgs_en/img_12.jpg --use_angle_cls true --lang en --use_gpu false

		PDF file is also supported, you can infer the first few pages by using the page_num parameter, the default is 0, which means infer all pages:
			paddleocr --image_dir ./xxx.pdf --use_angle_cls true --use_gpu false --page_num 2

		Only detection: set --rec to false.
			paddleocr --image_dir ./imgs_en/img_12.jpg --rec false

		Only recognition: set --det to false.
			paddleocr --image_dir ./imgs_words_en/word_10.png --det false --lang en

	- Multi-language model.
		PaddleOCR currently supports 80 languages, which can be switched by modifying the --lang parameter.
			paddleocr --image_dir ./doc/imgs_en/254.jpg --lang=en

[-] Usage (Python inference for PP-OCR Model Zoo).
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/inference_ppocr_en.md
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/models_list_en.md

	- Text detection model inference.
		Download DB text detection inference model:
			wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar
			tar xf ch_PP-OCRv3_det_infer.tar

		Run inference:
			python tools/infer/predict_det.py --image_dir="./doc/imgs/00018069.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/"
			python tools/infer/predict_det.py --image_dir="./doc/imgs/1.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --det_limit_type=max --det_limit_side_len=1216
			python tools/infer/predict_det.py --image_dir="./doc/imgs/1.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --use_gpu=False

	- Text recognition model inference.
		Lightweight Chinese recognition model inference:
			Download CRNN text recognition inference model:
				wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar
				tar xf ch_PP-OCRv3_rec_infer.tar

			Run inference:
				python tools/infer/predict_rec.py --image_dir="./doc/imgs_words_en/word_10.png" --rec_model_dir="./ch_PP-OCRv3_rec_infer/" --rec_image_shape=3,48,320

		English recognition model inference:
			For English recognition model inference, you can execute the following commands.
			You need to specify the dictionary path used by --rec_char_dict_path.

			Download en model:
				wget https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar
				tar xf en_PP-OCRv3_rec_infer.tar

			Run inference:
				python tools/infer/predict_rec.py --image_dir="./doc/imgs_words/en/word_1.png" --rec_model_dir="./en_PP-OCRv3_rec_infer/" --rec_char_dict_path="ppocr/utils/en_dict.txt"

		Multilingual model inference:
			If you need to predict other language models, when using inference model prediction, you need to specify the dictionary path used by --rec_char_dict_path.
			At the same time, in order to get the correct visualization results, You need to specify the visual font path through --vis_font_path.
			There are small language fonts provided by default under the doc/fonts path, such as Korean recognition.

			Download model:
				wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/multilingual/korean_mobile_v2.0_rec_infer.tar
				tar xf korean_mobile_v2.0_rec_infer.tar

				wget https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/korean_PP-OCRv3_rec_infer.tar
				tar xf korean_PP-OCRv3_rec_infer.tar

			Run inference:
				python tools/infer/predict_rec.py --image_dir="./doc/imgs_words/korean/1.jpg" --rec_model_dir="./korean_mobile_v2.0_rec_infer/" --rec_char_dict_path="ppocr/utils/dict/korean_dict.txt" --vis_font_path="doc/fonts/korean.ttf"
				python tools/infer/predict_rec.py --image_dir="./doc/imgs_words/korean/1.jpg" --rec_model_dir="./korean_PP-OCRv3_rec_infer/" --rec_char_dict_path="ppocr/utils/dict/korean_dict.txt" --vis_font_path="doc/fonts/korean.ttf"

	- Angle classification model inference.
		Download text angle class inference model:
			wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar
			tar xf ch_ppocr_mobile_v2.0_cls_infer.tar

		Run inference:
			python tools/infer/predict_cls.py --image_dir="./doc/imgs_words_en/word_10.png" --cls_model_dir="./ch_ppocr_mobile_v2.0_cls_infer/"

	- Text detection, angle classification, and recognition inference concatenation.
		The input shape used by the recognition model of PP-OCRv3 is 3, 48, 320.
		If you use other recognition models, you need to set the parameter --rec_image_shape according to the model.
		In addition, the rec_algorithm used by the recognition model of PP-OCRv3 is SVTR_LCNet by default.
		Note the difference from the original SVTR.

		image_dir: specifies the path of a single image or a folder of images.
		det_model_dir: specifies the path to detection inference model.
		cls_model_dir: specifies the path to angle classification inference model.
		rec_model_dir: specifies the path to identify the inference model.
		use_angle_cls: controls whether to enable the angle classification model.
		use_mp: specifies whether to use multi-process to infer.
		total_process_num: specifies the number of processs when using multi-process.
		draw_img_save_dir: The saving folder of the system's tandem prediction OCR results. Default: ./inference_results folder.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/inference_args_en.md

		Use direction classifier:
			python tools/infer/predict_system.py --image_dir="./doc/imgs/00018069.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --cls_model_dir="./cls/" --rec_model_dir="./ch_PP-OCRv3_rec_infer/" --use_angle_cls=true
		Do not use direction classifier:
			python tools/infer/predict_system.py --image_dir="./doc/imgs/00018069.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --rec_model_dir="./ch_PP-OCRv3_rec_infer/" --use_angle_cls=false
		Use multi-process:
			python tools/infer/predict_system.py --image_dir="./doc/imgs/00018069.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --rec_model_dir="./ch_PP-OCRv3_rec_infer/" --use_angle_cls=false --use_mp=True --total_process_num=6
			python tools/infer/predict_system.py --image_dir="./doc/imgs/korean_1.jpg" --det_model_dir="./Multilingual_PP-OCRv3_det_infer/" --cls_model_dir="./ch_ppocr_mobile_v2.0_cls_infer/" --rec_model_dir="./korean_PP-OCRv3_rec_infer/" --rec_char_dict_path="ppocr/utils/dict/korean_dict.txt" --vis_font_path="doc/fonts/korean.ttf" --use_angle_cls=true --use_mp=true --total_process_num=6
		Use PDF files:
			You can infer the first few pages by using the `page_num` parameter, the default is 0, which means infer all pages

			python tools/infer/predict_system.py --image_dir="./xxx.pdf" --det_model_dir="./ch_PP-OCRv3_det_infer/" --cls_model_dir="./ch_ppocr_mobile_v2.0_cls_infer/" --rec_model_dir="./ch_PP-OCRv3_rec_infer/" --use_angle_cls=true --page_num=2

	- TensorRT inference.
		Paddle Inference ensembles TensorRT using subgraph mode.
		For GPU deployment scenarios, TensorRT can optimize some subgraphs, including horizontal and vertical integration of OPs, filter redundant OPs, and automatically select the optimal OP kernels for to speed up inference.

		You need to do the following 2 steps for inference using TRT.
		(1) Collect the dynamic shape information of the model about a specific dataset and store it in a file.
		(2) Load the dynamic shape information file for TRT inference.

		python tools/infer/predict_det.py --image_dir="./doc/imgs/1.jpg" --det_model_dir="./ch_PP-OCRv3_det_infer/" --use_tensorrt=True

[-] Usage (PP-Structure).
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart_en.md

	- Image orientation + layout analysis + table recognition.
		paddleocr --image_dir=ppstructure/docs/table/1.png --type=structure --image_orientation=true

	- Layout analysis + table recognition.
		paddleocr --image_dir=ppstructure/docs/table/1.png --type=structure

	- Layout analysis.
		paddleocr --image_dir=ppstructure/docs/table/1.png --type=structure --table=false --ocr=false

	- Table recognition.
		paddleocr --image_dir=ppstructure/docs/table/table.jpg --type=structure --layout=false

	- Key information extraction.
		Recovery by using PDF parse (only support pdf as input):
			paddleocr --image_dir=ppstructure/recovery/UnrealText.pdf --type=structure --recovery=true --use_pdf2docx_api=true

		Recovery by using OCR:
			paddleocr --image_dir=ppstructure/docs/table/1.png --type=structure --recovery=true --lang='en'

[-] Usage (Python inference for PP-Structure).
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart_en.md
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/models_list_en.md

	- Layout structured analysis.
		cd ${PaddleOCR_HOME}/ppstructure

		Download model:
			mkdir inference && cd inference
			# Download the PP-StructureV2 layout analysis model and unzip it
			wget https://paddleocr.bj.bcebos.com/ppstructure/models/layout/picodet_lcnet_x1_0_layout_infer.tar && tar xf picodet_lcnet_x1_0_layout_infer.tar
			# Download the PP-OCRv3 text detection model and unzip it
			wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar && tar xf ch_PP-OCRv3_det_infer.tar
			# Download the PP-OCRv3 text recognition model and unzip it
			wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar && tar xf ch_PP-OCRv3_rec_infer.tar
			# Download the PP-StructureV2 form recognition model and unzip it
			wget https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/ch_ppstructure_mobile_v2.0_SLANet_infer.tar && tar xf ch_ppstructure_mobile_v2.0_SLANet_infer.tar
			cd ..

		Layout analysis + table recognition:
			python predict_system.py --det_model_dir=inference/ch_PP-OCRv3_det_infer \
				--rec_model_dir=inference/ch_PP-OCRv3_rec_infer \
				--table_model_dir=inference/ch_ppstructure_mobile_v2.0_SLANet_infer \
				--layout_model_dir=inference/picodet_lcnet_x1_0_layout_infer \
				--image_dir=./docs/table/1.png \
				--rec_char_dict_path=../ppocr/utils/ppocr_keys_v1.txt \
				--table_char_dict_path=../ppocr/utils/dict/table_structure_dict_ch.txt \
				--output=../output \
				--vis_font_path=../doc/fonts/simfang.ttf

		Layout analysis:
			python predict_system.py --layout_model_dir=inference/picodet_lcnet_x1_0_layout_infer \
				--image_dir=./docs/table/1.png \
				--output=../output \
				--table=false \
				--ocr=false

		Table recognition:
			python predict_system.py --det_model_dir=inference/ch_PP-OCRv3_det_infer \
				--rec_model_dir=inference/ch_PP-OCRv3_rec_infer \
				--table_model_dir=inference/ch_ppstructure_mobile_v2.0_SLANet_infer \
				--image_dir=./docs/table/table.jpg \
				--rec_char_dict_path=../ppocr/utils/ppocr_keys_v1.txt \
				--table_char_dict_path=../ppocr/utils/dict/table_structure_dict_ch.txt \
				--output=../output \
				--vis_font_path=../doc/fonts/simfang.ttf \
				--layout=false

	- Key information extraction.
		cd ${PaddleOCR_HOME}/ppstructure

		SER:
			Download model:
				mkdir inference && cd inference
				wget https://paddleocr.bj.bcebos.com/ppstructure/models/vi_layoutxlm/ser_vi_layoutxlm_xfund_infer.tar && tar -xf ser_vi_layoutxlm_xfund_infer.tar
				cd ..

			python predict_system.py \
				--kie_algorithm=LayoutXLM \
				--ser_model_dir=./inference/ser_vi_layoutxlm_xfund_infer \
				--image_dir=./docs/kie/input/zh_val_42.jpg \
				--ser_dict_path=../ppocr/utils/dict/kie_dict/xfund_class_list.txt \
				--vis_font_path=../doc/fonts/simfang.ttf \
				--ocr_order_method="tb-yx" \
				--mode=kie

		RE+SER:
			Download model:
				mkdir inference && cd inference
				wget https://paddleocr.bj.bcebos.com/ppstructure/models/vi_layoutxlm/ser_vi_layoutxlm_xfund_infer.tar && tar -xf ser_vi_layoutxlm_xfund_infer.tar
				wget https://paddleocr.bj.bcebos.com/ppstructure/models/vi_layoutxlm/re_vi_layoutxlm_xfund_infer.tar && tar -xf re_vi_layoutxlm_xfund_infer.tar
				cd ..

			python predict_system.py \
				--kie_algorithm=LayoutXLM \
				--re_model_dir=./inference/re_vi_layoutxlm_xfund_infer \
				--ser_model_dir=./inference/ser_vi_layoutxlm_xfund_infer \
				--image_dir=./docs/kie/input/zh_val_42.jpg \
				--ser_dict_path=../ppocr/utils/dict/kie_dict/xfund_class_list.txt \
				--vis_font_path=../doc/fonts/simfang.ttf \
				--ocr_order_method="tb-yx" \
				--mode=kie

[-] Training.
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/training_en.md

	- Dataset.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/ocr_datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/vertical_and_multilingual_datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/handwritten_datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/kie_datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/layout_datasets_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/dataset/table_datasets_en.md

		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/config_en.md

	- Detection.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/detection_en.md

	- Recognition.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/recognition_en.md

	- Table recognition.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/table_recognition_en.md
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/algorithm_table_master_en.md

		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/configs/table/table_master.yml
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/configs/table/SLANet.yml

		Data preparation:
			Dataset format.
				Same as PubTabNet format.
			Data download.
			Dataset generation.
			Data annotation.

			Split PubTabNet v2 dataset.
				Refer to split_pubtabnet_v2_jsonl() in ${SWLP_HOME}/app/document/pubtabnet_data_test.py.

			cd ${PaddleOCR_HOME}
			mkdir -p train_data/table
			ln -s /home/sangwook/work/dataset/text/table/pubtabnet_v2 pubtabnet
				Refer to Train.dataset.data_dir, Train.dataset.label_file_list, Eval.dataset.data_dir & Eval.dataset.label_file_list in ${PaddleOCR_HOME}/configs/table/SLANet.yml.

		Training:
			Start training:
				Specify the single card training(Long training time, not recommended):
					python tools/train.py -c configs/table/SLANet.yml
					python tools/train.py -c configs/table/table_master.yml
					python tools/train.py -c configs/table/table_mv3.yml
						MobileNetV3.

				Specify the card number through --gpus:
					python -m paddle.distributed.launch --gpus '0,1,2,3' tools/train.py -c configs/table/SLANet.yml
					python -m paddle.distributed.launch --gpus '0,1,2,3' tools/train.py -c configs/table/table_master.yml
					python -m paddle.distributed.launch --gpus '0,1,2,3' tools/train.py -c configs/table/table_mv3.yml
						MobileNetV3.

			Resume training:
				python tools/train.py -c configs/table/SLANet.yml -o Global.checkpoints=./your/trained/model

			Training with new backbone:

			Mixed precision training:
				python tools/train.py -c configs/table/SLANet.yml \
					-o Global.pretrained_model=./pretrain_models/SLANet/best_accuracy \
					Global.use_amp=True Global.scale_loss=1024.0 Global.use_dynamic_loss_scaling=True

			Distributed training:

			Fine-tuning:

		Evaluation and test:
			Evaluation:
				GPU evaluation, Global.checkpoints is the weight to be tested:
					python -m paddle.distributed.launch --gpus '0' tools/eval.py -c configs/table/SLANet.yml -o Global.checkpoints={path/to/weights}/best_accuracy

			Test table structure recognition effect:
				Predict table image:
					python tools/infer_table.py -c configs/table/SLANet.yml -o Global.pretrained_model={path/to/weights}/best_accuracy  Global.infer_img=ppstructure/docs/table/table.jpg

		Visualizing:
			visualdl --logdir ./log
			visualdl --logdir ./log --port 8040
			visualdl --logdir ./output/table_master --host 0.0.0.0 --port 15003

		Model export and prediction:
			Model export:
				python tools/export_model.py -c configs/table/SLANet.yml -o Global.pretrained_model=./pretrain_models/SLANet/best_accuracy  Global.save_inference_dir=./inference/SLANet/
					-c: set the training algorithm yml configuration file.
					-o: set optional parameters.
					Global.pretrained_model: set the training model address to be converted without adding the file suffix .pdmodel, .pdopt or .pdparams.
					Global.save_inference_dir: set the address where the converted model will be saved.

			Prediction:
				python table/predict_structure.py \
					--table_model_dir={path/to/inference model} \
					--table_char_dict_path=../ppocr/utils/dict/table_structure_dict_ch.txt \
					--image_dir=docs/table/table.jpg \
					--output=../output/table

[-] Finetuning.
	https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/finetune_en.md

[-] Installation (Ubuntu).
	- Install PaddleOCR.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/quickstart_en.md

		sudo apt install libcudnn8 libcublas11

		conda create --name ppocr python=3.10

		pip install numpy matplotlib pillow opencv-python fitz
		pip install paddlepaddle-gpu -i https://pypi.tuna.tsinghua.edu.cn/simple
		pip install paddleocr>=2.0.1

	- Install PP-Structure.
		https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart_en.md

		For CUDA 9 or 10:
			python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple
		For no GPU:
			python -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple

		Install paddleocr:
			pip install "paddleocr>=2.6.0.3"
		Install the image direction classification dependency package paddleclas (if you do not use the image direction classification, you can skip it):
			pip install paddleclas>=2.4.3

[-] Troubleshooting (Ubuntu).
	- <error> ImportError: /lib/x86_64-linux-gnu/libssl.so.1.1: version 'OPENSSL_1_1_1' not found
		<solution>
			https://stackoverflow.com/questions/72133316/libssl-so-1-1-cannot-open-shared-object-file-no-such-file-or-directory

			It is risky to install openssl-1.1.1o on Ubuntu 22.04 as it supports openssl-3.0.2.
			A more preferable way would be to build and keep the libssl.so.1.1 and libcrypto.so.1.1 libraries away from root and export LD_LIBRARY_PATH as needed.

			get https://www.openssl.org/source/openssl-1.1.1o.tar.gz
			tar -zxvf openssl-1.1.1o.tar.gz
			cd openssl-1.1.1o
			./config
			make
			make test
			sudo make install

			(Optional) ln -s /usr/local/lib/libssl.so.1.1 /usr/lib/libssl.so.1.1
			(Optional) ln -s /usr/local/lib/libcrypto.so.1.1 /usr/lib/libcrypto.so.1.1
